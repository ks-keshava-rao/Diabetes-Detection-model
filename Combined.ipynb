{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes_Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORNmh3nxKDNfCdRBx9FZLn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kskrao219/Diabetes-Detection-model/blob/main/Combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsYkxyoKxi5Q"
      },
      "source": [
        "#Neural Network Design\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyST6Lk2wDVH"
      },
      "source": [
        "### Dataset Description \n",
        "#### 1. Number of times pregnant\n",
        "#### 2.Plasma glucose concentration a 2 hours in an oral glucose\n",
        "#### 3 .Diastolic blood pressure (mmhg)\n",
        "#### 4 .Triceps skin fold thickness(mm)\n",
        "#### 5 .2 hr serum insulin (mu U/ml)\n",
        "#### 6 .Body mass index (weight in kg/(height in m)^2)\n",
        "#### 7. Diabetes pedigree function\n",
        "#### 8. Age (years) \n",
        "#### 9. Class variable(0 or 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzjWNPtOoe1w"
      },
      "source": [
        "from numpy import loadtxt\n",
        "#Sequential is used to creat empty stack of ex hidden layer , input layers\n",
        "from keras.models import Sequential\n",
        "#DenseNets\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "from google.colab import files\n",
        "import io\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "DCoAsXIToo5w",
        "outputId": "e833dbc2-fd6b-44ef-af94-604de8af87dc"
      },
      "source": [
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e749937-7fc2-46b9-8701-8ae36bc77571\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e749937-7fc2-46b9-8701-8ae36bc77571\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving diabetes.csv to diabetes.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdDG9q4toxUO"
      },
      "source": [
        " dataset = loadtxt('diabetes.csv', delimiter = ',' )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCLvaNV-zkai"
      },
      "source": [
        "x = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqLYA_vbVk17",
        "outputId": "9783c45e-03cf-4f12-e7db-57dea56a4b47"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCxnC_3TWNaI",
        "outputId": "ef1647f3-6074-4534-9954-5f71252feea8"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FJnDaQYWSqS"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation ='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2jMAlnvXYwW",
        "outputId": "ba749a42-f89f-454f-e3c6-f32dfdb78db9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itN084V2YB4V"
      },
      "source": [
        "*italicized text*#Model optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWuCZhaZXzge",
        "outputId": "4bf98bea-3822-49d1-e565-08d4ba81e5a5"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#Training model\n",
        "model.fit(x,y,epochs=282, batch_size=20)\n",
        "#model.evaluate gives overall accuracy\n",
        "_,accuracy = model.evaluate(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/282\n",
            "39/39 [==============================] - 1s 922us/step - loss: 0.4490 - accuracy: 0.7942\n",
            "Epoch 2/282\n",
            "39/39 [==============================] - 0s 834us/step - loss: 0.4259 - accuracy: 0.7917\n",
            "Epoch 3/282\n",
            "39/39 [==============================] - 0s 878us/step - loss: 0.4285 - accuracy: 0.8013\n",
            "Epoch 4/282\n",
            "39/39 [==============================] - 0s 834us/step - loss: 0.4386 - accuracy: 0.7808\n",
            "Epoch 5/282\n",
            "39/39 [==============================] - 0s 894us/step - loss: 0.4429 - accuracy: 0.7866\n",
            "Epoch 6/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8129\n",
            "Epoch 7/282\n",
            "39/39 [==============================] - 0s 857us/step - loss: 0.4573 - accuracy: 0.7766\n",
            "Epoch 8/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7876\n",
            "Epoch 9/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7743\n",
            "Epoch 10/282\n",
            "39/39 [==============================] - 0s 926us/step - loss: 0.4760 - accuracy: 0.7898\n",
            "Epoch 11/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7699\n",
            "Epoch 12/282\n",
            "39/39 [==============================] - 0s 987us/step - loss: 0.4571 - accuracy: 0.7620\n",
            "Epoch 13/282\n",
            "39/39 [==============================] - 0s 866us/step - loss: 0.4436 - accuracy: 0.8073\n",
            "Epoch 14/282\n",
            "39/39 [==============================] - 0s 816us/step - loss: 0.4452 - accuracy: 0.7736\n",
            "Epoch 15/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7903\n",
            "Epoch 16/282\n",
            "39/39 [==============================] - 0s 860us/step - loss: 0.4458 - accuracy: 0.8013\n",
            "Epoch 17/282\n",
            "39/39 [==============================] - 0s 876us/step - loss: 0.4619 - accuracy: 0.7870\n",
            "Epoch 18/282\n",
            "39/39 [==============================] - 0s 918us/step - loss: 0.4310 - accuracy: 0.7807\n",
            "Epoch 19/282\n",
            "39/39 [==============================] - 0s 906us/step - loss: 0.4314 - accuracy: 0.7875\n",
            "Epoch 20/282\n",
            "39/39 [==============================] - 0s 875us/step - loss: 0.4696 - accuracy: 0.7718\n",
            "Epoch 21/282\n",
            "39/39 [==============================] - 0s 894us/step - loss: 0.4705 - accuracy: 0.7734\n",
            "Epoch 22/282\n",
            "39/39 [==============================] - 0s 894us/step - loss: 0.4396 - accuracy: 0.7743\n",
            "Epoch 23/282\n",
            "39/39 [==============================] - 0s 936us/step - loss: 0.4276 - accuracy: 0.7956\n",
            "Epoch 24/282\n",
            "39/39 [==============================] - 0s 825us/step - loss: 0.4752 - accuracy: 0.7758\n",
            "Epoch 25/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7964\n",
            "Epoch 26/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7910\n",
            "Epoch 27/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8070\n",
            "Epoch 28/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7824\n",
            "Epoch 29/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7603\n",
            "Epoch 30/282\n",
            "39/39 [==============================] - 0s 845us/step - loss: 0.4750 - accuracy: 0.7633\n",
            "Epoch 31/282\n",
            "39/39 [==============================] - 0s 870us/step - loss: 0.4129 - accuracy: 0.8081\n",
            "Epoch 32/282\n",
            "39/39 [==============================] - 0s 850us/step - loss: 0.4706 - accuracy: 0.7790\n",
            "Epoch 33/282\n",
            "39/39 [==============================] - 0s 859us/step - loss: 0.4469 - accuracy: 0.7817\n",
            "Epoch 34/282\n",
            "39/39 [==============================] - 0s 906us/step - loss: 0.4042 - accuracy: 0.8123\n",
            "Epoch 35/282\n",
            "39/39 [==============================] - 0s 896us/step - loss: 0.4463 - accuracy: 0.7792\n",
            "Epoch 36/282\n",
            "39/39 [==============================] - 0s 876us/step - loss: 0.4611 - accuracy: 0.7787\n",
            "Epoch 37/282\n",
            "39/39 [==============================] - 0s 938us/step - loss: 0.4422 - accuracy: 0.7884\n",
            "Epoch 38/282\n",
            "39/39 [==============================] - 0s 996us/step - loss: 0.4514 - accuracy: 0.7668\n",
            "Epoch 39/282\n",
            "39/39 [==============================] - 0s 909us/step - loss: 0.4513 - accuracy: 0.7772\n",
            "Epoch 40/282\n",
            "39/39 [==============================] - 0s 946us/step - loss: 0.4181 - accuracy: 0.7991\n",
            "Epoch 41/282\n",
            "39/39 [==============================] - 0s 899us/step - loss: 0.4491 - accuracy: 0.7637\n",
            "Epoch 42/282\n",
            "39/39 [==============================] - 0s 932us/step - loss: 0.4388 - accuracy: 0.7994\n",
            "Epoch 43/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7889\n",
            "Epoch 44/282\n",
            "39/39 [==============================] - 0s 900us/step - loss: 0.4707 - accuracy: 0.7832\n",
            "Epoch 45/282\n",
            "39/39 [==============================] - 0s 953us/step - loss: 0.4356 - accuracy: 0.7902\n",
            "Epoch 46/282\n",
            "39/39 [==============================] - 0s 950us/step - loss: 0.4277 - accuracy: 0.7946\n",
            "Epoch 47/282\n",
            "39/39 [==============================] - 0s 963us/step - loss: 0.4774 - accuracy: 0.7645\n",
            "Epoch 48/282\n",
            "39/39 [==============================] - 0s 939us/step - loss: 0.4266 - accuracy: 0.7883\n",
            "Epoch 49/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7690\n",
            "Epoch 50/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7846\n",
            "Epoch 51/282\n",
            "39/39 [==============================] - 0s 929us/step - loss: 0.4644 - accuracy: 0.7698\n",
            "Epoch 52/282\n",
            "39/39 [==============================] - 0s 950us/step - loss: 0.4354 - accuracy: 0.7912\n",
            "Epoch 53/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7750\n",
            "Epoch 54/282\n",
            "39/39 [==============================] - 0s 926us/step - loss: 0.4662 - accuracy: 0.7602\n",
            "Epoch 55/282\n",
            "39/39 [==============================] - 0s 904us/step - loss: 0.4666 - accuracy: 0.7760\n",
            "Epoch 56/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.8013\n",
            "Epoch 57/282\n",
            "39/39 [==============================] - 0s 880us/step - loss: 0.4312 - accuracy: 0.7952\n",
            "Epoch 58/282\n",
            "39/39 [==============================] - 0s 927us/step - loss: 0.4746 - accuracy: 0.7823\n",
            "Epoch 59/282\n",
            "39/39 [==============================] - 0s 967us/step - loss: 0.4247 - accuracy: 0.7861\n",
            "Epoch 60/282\n",
            "39/39 [==============================] - 0s 948us/step - loss: 0.4175 - accuracy: 0.8075\n",
            "Epoch 61/282\n",
            "39/39 [==============================] - 0s 940us/step - loss: 0.4517 - accuracy: 0.7804\n",
            "Epoch 62/282\n",
            "39/39 [==============================] - 0s 828us/step - loss: 0.4662 - accuracy: 0.7649\n",
            "Epoch 63/282\n",
            "39/39 [==============================] - 0s 984us/step - loss: 0.4324 - accuracy: 0.8067\n",
            "Epoch 64/282\n",
            "39/39 [==============================] - 0s 999us/step - loss: 0.4708 - accuracy: 0.7768\n",
            "Epoch 65/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.7897\n",
            "Epoch 66/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7565\n",
            "Epoch 67/282\n",
            "39/39 [==============================] - 0s 953us/step - loss: 0.4575 - accuracy: 0.7801\n",
            "Epoch 68/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7758\n",
            "Epoch 69/282\n",
            "39/39 [==============================] - 0s 862us/step - loss: 0.4376 - accuracy: 0.8019\n",
            "Epoch 70/282\n",
            "39/39 [==============================] - 0s 887us/step - loss: 0.4386 - accuracy: 0.7967\n",
            "Epoch 71/282\n",
            "39/39 [==============================] - 0s 856us/step - loss: 0.4410 - accuracy: 0.7926\n",
            "Epoch 72/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7903\n",
            "Epoch 73/282\n",
            "39/39 [==============================] - 0s 954us/step - loss: 0.4542 - accuracy: 0.7592\n",
            "Epoch 74/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7889\n",
            "Epoch 75/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7774\n",
            "Epoch 76/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7826\n",
            "Epoch 77/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7836\n",
            "Epoch 78/282\n",
            "39/39 [==============================] - 0s 978us/step - loss: 0.4369 - accuracy: 0.8015\n",
            "Epoch 79/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7947\n",
            "Epoch 80/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7699\n",
            "Epoch 81/282\n",
            "39/39 [==============================] - 0s 890us/step - loss: 0.4406 - accuracy: 0.7883\n",
            "Epoch 82/282\n",
            "39/39 [==============================] - 0s 833us/step - loss: 0.4293 - accuracy: 0.7985\n",
            "Epoch 83/282\n",
            "39/39 [==============================] - 0s 857us/step - loss: 0.4052 - accuracy: 0.8018\n",
            "Epoch 84/282\n",
            "39/39 [==============================] - 0s 866us/step - loss: 0.4432 - accuracy: 0.8034\n",
            "Epoch 85/282\n",
            "39/39 [==============================] - 0s 803us/step - loss: 0.4594 - accuracy: 0.7546\n",
            "Epoch 86/282\n",
            "39/39 [==============================] - 0s 858us/step - loss: 0.4548 - accuracy: 0.7896\n",
            "Epoch 87/282\n",
            "39/39 [==============================] - 0s 987us/step - loss: 0.4509 - accuracy: 0.7819\n",
            "Epoch 88/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7725\n",
            "Epoch 89/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8034\n",
            "Epoch 90/282\n",
            "39/39 [==============================] - 0s 913us/step - loss: 0.4409 - accuracy: 0.7684\n",
            "Epoch 91/282\n",
            "39/39 [==============================] - 0s 854us/step - loss: 0.4142 - accuracy: 0.8164\n",
            "Epoch 92/282\n",
            "39/39 [==============================] - 0s 899us/step - loss: 0.4378 - accuracy: 0.7942\n",
            "Epoch 93/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7734\n",
            "Epoch 94/282\n",
            "39/39 [==============================] - 0s 912us/step - loss: 0.4573 - accuracy: 0.7767\n",
            "Epoch 95/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7810\n",
            "Epoch 96/282\n",
            "39/39 [==============================] - 0s 900us/step - loss: 0.4543 - accuracy: 0.7915\n",
            "Epoch 97/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7904\n",
            "Epoch 98/282\n",
            "39/39 [==============================] - 0s 937us/step - loss: 0.4288 - accuracy: 0.7911\n",
            "Epoch 99/282\n",
            "39/39 [==============================] - 0s 928us/step - loss: 0.4478 - accuracy: 0.7877\n",
            "Epoch 100/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7786\n",
            "Epoch 101/282\n",
            "39/39 [==============================] - 0s 967us/step - loss: 0.4718 - accuracy: 0.7698\n",
            "Epoch 102/282\n",
            "39/39 [==============================] - 0s 952us/step - loss: 0.4245 - accuracy: 0.8053\n",
            "Epoch 103/282\n",
            "39/39 [==============================] - 0s 933us/step - loss: 0.4245 - accuracy: 0.7979\n",
            "Epoch 104/282\n",
            "39/39 [==============================] - 0s 940us/step - loss: 0.4121 - accuracy: 0.7974\n",
            "Epoch 105/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7640\n",
            "Epoch 106/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7963\n",
            "Epoch 107/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8137\n",
            "Epoch 108/282\n",
            "39/39 [==============================] - 0s 988us/step - loss: 0.5197 - accuracy: 0.7431\n",
            "Epoch 109/282\n",
            "39/39 [==============================] - 0s 870us/step - loss: 0.4808 - accuracy: 0.7598\n",
            "Epoch 110/282\n",
            "39/39 [==============================] - 0s 875us/step - loss: 0.4359 - accuracy: 0.7895\n",
            "Epoch 111/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8201\n",
            "Epoch 112/282\n",
            "39/39 [==============================] - 0s 924us/step - loss: 0.4713 - accuracy: 0.7811\n",
            "Epoch 113/282\n",
            "39/39 [==============================] - 0s 964us/step - loss: 0.4576 - accuracy: 0.7955\n",
            "Epoch 114/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7945\n",
            "Epoch 115/282\n",
            "39/39 [==============================] - 0s 970us/step - loss: 0.4367 - accuracy: 0.7900\n",
            "Epoch 116/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7768\n",
            "Epoch 117/282\n",
            "39/39 [==============================] - 0s 922us/step - loss: 0.4769 - accuracy: 0.7815\n",
            "Epoch 118/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7915\n",
            "Epoch 119/282\n",
            "39/39 [==============================] - 0s 926us/step - loss: 0.4549 - accuracy: 0.7769\n",
            "Epoch 120/282\n",
            "39/39 [==============================] - 0s 932us/step - loss: 0.4781 - accuracy: 0.7699\n",
            "Epoch 121/282\n",
            "39/39 [==============================] - 0s 972us/step - loss: 0.4206 - accuracy: 0.7888\n",
            "Epoch 122/282\n",
            "39/39 [==============================] - 0s 955us/step - loss: 0.4644 - accuracy: 0.7617\n",
            "Epoch 123/282\n",
            "39/39 [==============================] - 0s 950us/step - loss: 0.4723 - accuracy: 0.7726\n",
            "Epoch 124/282\n",
            "39/39 [==============================] - 0s 975us/step - loss: 0.4778 - accuracy: 0.7670\n",
            "Epoch 125/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7774\n",
            "Epoch 126/282\n",
            "39/39 [==============================] - 0s 958us/step - loss: 0.4713 - accuracy: 0.7594\n",
            "Epoch 127/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7943\n",
            "Epoch 128/282\n",
            "39/39 [==============================] - 0s 987us/step - loss: 0.4379 - accuracy: 0.7950\n",
            "Epoch 129/282\n",
            "39/39 [==============================] - 0s 975us/step - loss: 0.4441 - accuracy: 0.7845\n",
            "Epoch 130/282\n",
            "39/39 [==============================] - 0s 963us/step - loss: 0.4236 - accuracy: 0.8007\n",
            "Epoch 131/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7991\n",
            "Epoch 132/282\n",
            "39/39 [==============================] - 0s 938us/step - loss: 0.4246 - accuracy: 0.7892\n",
            "Epoch 133/282\n",
            "39/39 [==============================] - 0s 938us/step - loss: 0.4514 - accuracy: 0.7993\n",
            "Epoch 134/282\n",
            "39/39 [==============================] - 0s 916us/step - loss: 0.4582 - accuracy: 0.7668\n",
            "Epoch 135/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7494\n",
            "Epoch 136/282\n",
            "39/39 [==============================] - 0s 901us/step - loss: 0.4678 - accuracy: 0.7829\n",
            "Epoch 137/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7567\n",
            "Epoch 138/282\n",
            "39/39 [==============================] - 0s 883us/step - loss: 0.4831 - accuracy: 0.7772\n",
            "Epoch 139/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7824\n",
            "Epoch 140/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7935\n",
            "Epoch 141/282\n",
            "39/39 [==============================] - 0s 926us/step - loss: 0.4576 - accuracy: 0.7925\n",
            "Epoch 142/282\n",
            "39/39 [==============================] - 0s 913us/step - loss: 0.4604 - accuracy: 0.7700\n",
            "Epoch 143/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7784\n",
            "Epoch 144/282\n",
            "39/39 [==============================] - 0s 955us/step - loss: 0.4408 - accuracy: 0.7882\n",
            "Epoch 145/282\n",
            "39/39 [==============================] - 0s 912us/step - loss: 0.4300 - accuracy: 0.7844\n",
            "Epoch 146/282\n",
            "39/39 [==============================] - 0s 950us/step - loss: 0.4293 - accuracy: 0.7906\n",
            "Epoch 147/282\n",
            "39/39 [==============================] - 0s 946us/step - loss: 0.4645 - accuracy: 0.7800\n",
            "Epoch 148/282\n",
            "39/39 [==============================] - 0s 879us/step - loss: 0.4209 - accuracy: 0.8072\n",
            "Epoch 149/282\n",
            "39/39 [==============================] - 0s 894us/step - loss: 0.4496 - accuracy: 0.7659\n",
            "Epoch 150/282\n",
            "39/39 [==============================] - 0s 848us/step - loss: 0.4488 - accuracy: 0.7918\n",
            "Epoch 151/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7640\n",
            "Epoch 152/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8058\n",
            "Epoch 153/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7807\n",
            "Epoch 154/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7697\n",
            "Epoch 155/282\n",
            "39/39 [==============================] - 0s 982us/step - loss: 0.4379 - accuracy: 0.7895\n",
            "Epoch 156/282\n",
            "39/39 [==============================] - 0s 915us/step - loss: 0.4474 - accuracy: 0.7810\n",
            "Epoch 157/282\n",
            "39/39 [==============================] - 0s 896us/step - loss: 0.4474 - accuracy: 0.7818\n",
            "Epoch 158/282\n",
            "39/39 [==============================] - 0s 961us/step - loss: 0.4623 - accuracy: 0.7785\n",
            "Epoch 159/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7772\n",
            "Epoch 160/282\n",
            "39/39 [==============================] - 0s 939us/step - loss: 0.4628 - accuracy: 0.7658\n",
            "Epoch 161/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7993\n",
            "Epoch 162/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.7923\n",
            "Epoch 163/282\n",
            "39/39 [==============================] - 0s 962us/step - loss: 0.4191 - accuracy: 0.8221\n",
            "Epoch 164/282\n",
            "39/39 [==============================] - 0s 954us/step - loss: 0.4343 - accuracy: 0.7800\n",
            "Epoch 165/282\n",
            "39/39 [==============================] - 0s 929us/step - loss: 0.4460 - accuracy: 0.7917\n",
            "Epoch 166/282\n",
            "39/39 [==============================] - 0s 923us/step - loss: 0.4215 - accuracy: 0.8062\n",
            "Epoch 167/282\n",
            "39/39 [==============================] - 0s 928us/step - loss: 0.4765 - accuracy: 0.7536\n",
            "Epoch 168/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7830\n",
            "Epoch 169/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7782\n",
            "Epoch 170/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7697\n",
            "Epoch 171/282\n",
            "39/39 [==============================] - 0s 991us/step - loss: 0.4867 - accuracy: 0.7755\n",
            "Epoch 172/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8130\n",
            "Epoch 173/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7904\n",
            "Epoch 174/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7947\n",
            "Epoch 175/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8136\n",
            "Epoch 176/282\n",
            "39/39 [==============================] - 0s 997us/step - loss: 0.4315 - accuracy: 0.7978\n",
            "Epoch 177/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7851\n",
            "Epoch 178/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7823\n",
            "Epoch 179/282\n",
            "39/39 [==============================] - 0s 910us/step - loss: 0.4412 - accuracy: 0.7908\n",
            "Epoch 180/282\n",
            "39/39 [==============================] - 0s 910us/step - loss: 0.4295 - accuracy: 0.7938\n",
            "Epoch 181/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7852\n",
            "Epoch 182/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7901\n",
            "Epoch 183/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7955\n",
            "Epoch 184/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7861\n",
            "Epoch 185/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.7995\n",
            "Epoch 186/282\n",
            "39/39 [==============================] - 0s 941us/step - loss: 0.4361 - accuracy: 0.7871\n",
            "Epoch 187/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7872\n",
            "Epoch 188/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8129\n",
            "Epoch 189/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7973\n",
            "Epoch 190/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.7944\n",
            "Epoch 191/282\n",
            "39/39 [==============================] - 0s 957us/step - loss: 0.4448 - accuracy: 0.7767\n",
            "Epoch 192/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7753\n",
            "Epoch 193/282\n",
            "39/39 [==============================] - 0s 952us/step - loss: 0.4707 - accuracy: 0.7600\n",
            "Epoch 194/282\n",
            "39/39 [==============================] - 0s 998us/step - loss: 0.4431 - accuracy: 0.7964\n",
            "Epoch 195/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7782\n",
            "Epoch 196/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7870\n",
            "Epoch 197/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8030\n",
            "Epoch 198/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7914\n",
            "Epoch 199/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.7958\n",
            "Epoch 200/282\n",
            "39/39 [==============================] - 0s 928us/step - loss: 0.4587 - accuracy: 0.7772\n",
            "Epoch 201/282\n",
            "39/39 [==============================] - 0s 943us/step - loss: 0.4693 - accuracy: 0.7627\n",
            "Epoch 202/282\n",
            "39/39 [==============================] - 0s 963us/step - loss: 0.4291 - accuracy: 0.7809\n",
            "Epoch 203/282\n",
            "39/39 [==============================] - 0s 894us/step - loss: 0.4261 - accuracy: 0.7980\n",
            "Epoch 204/282\n",
            "39/39 [==============================] - 0s 960us/step - loss: 0.4451 - accuracy: 0.7920\n",
            "Epoch 205/282\n",
            "39/39 [==============================] - 0s 926us/step - loss: 0.4217 - accuracy: 0.8146\n",
            "Epoch 206/282\n",
            "39/39 [==============================] - 0s 923us/step - loss: 0.4541 - accuracy: 0.7796\n",
            "Epoch 207/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7675\n",
            "Epoch 208/282\n",
            "39/39 [==============================] - 0s 937us/step - loss: 0.4489 - accuracy: 0.7787\n",
            "Epoch 209/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7858\n",
            "Epoch 210/282\n",
            "39/39 [==============================] - 0s 923us/step - loss: 0.4509 - accuracy: 0.7922\n",
            "Epoch 211/282\n",
            "39/39 [==============================] - 0s 955us/step - loss: 0.4607 - accuracy: 0.7733\n",
            "Epoch 212/282\n",
            "39/39 [==============================] - 0s 922us/step - loss: 0.4774 - accuracy: 0.7559\n",
            "Epoch 213/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.7855\n",
            "Epoch 214/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7885\n",
            "Epoch 215/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7718\n",
            "Epoch 216/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7770\n",
            "Epoch 217/282\n",
            "39/39 [==============================] - 0s 986us/step - loss: 0.4456 - accuracy: 0.7891\n",
            "Epoch 218/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4038 - accuracy: 0.7948\n",
            "Epoch 219/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7702\n",
            "Epoch 220/282\n",
            "39/39 [==============================] - 0s 999us/step - loss: 0.4622 - accuracy: 0.7828\n",
            "Epoch 221/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7884\n",
            "Epoch 222/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7796\n",
            "Epoch 223/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8025\n",
            "Epoch 224/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7793\n",
            "Epoch 225/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7636\n",
            "Epoch 226/282\n",
            "39/39 [==============================] - 0s 929us/step - loss: 0.4191 - accuracy: 0.8076\n",
            "Epoch 227/282\n",
            "39/39 [==============================] - 0s 983us/step - loss: 0.4639 - accuracy: 0.7726\n",
            "Epoch 228/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7881\n",
            "Epoch 229/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.7994\n",
            "Epoch 230/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7974\n",
            "Epoch 231/282\n",
            "39/39 [==============================] - 0s 950us/step - loss: 0.4890 - accuracy: 0.7857\n",
            "Epoch 232/282\n",
            "39/39 [==============================] - 0s 930us/step - loss: 0.4655 - accuracy: 0.7832\n",
            "Epoch 233/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7952\n",
            "Epoch 234/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7719\n",
            "Epoch 235/282\n",
            "39/39 [==============================] - 0s 954us/step - loss: 0.4274 - accuracy: 0.8016\n",
            "Epoch 236/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7960\n",
            "Epoch 237/282\n",
            "39/39 [==============================] - 0s 976us/step - loss: 0.4413 - accuracy: 0.7981\n",
            "Epoch 238/282\n",
            "39/39 [==============================] - 0s 958us/step - loss: 0.4373 - accuracy: 0.8046\n",
            "Epoch 239/282\n",
            "39/39 [==============================] - 0s 949us/step - loss: 0.4098 - accuracy: 0.8161\n",
            "Epoch 240/282\n",
            "39/39 [==============================] - 0s 982us/step - loss: 0.4231 - accuracy: 0.7921\n",
            "Epoch 241/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7649\n",
            "Epoch 242/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7708\n",
            "Epoch 243/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7907\n",
            "Epoch 244/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7959\n",
            "Epoch 245/282\n",
            "39/39 [==============================] - 0s 979us/step - loss: 0.4174 - accuracy: 0.7954\n",
            "Epoch 246/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7785\n",
            "Epoch 247/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7690\n",
            "Epoch 248/282\n",
            "39/39 [==============================] - 0s 998us/step - loss: 0.4129 - accuracy: 0.8015\n",
            "Epoch 249/282\n",
            "39/39 [==============================] - 0s 901us/step - loss: 0.4384 - accuracy: 0.8006\n",
            "Epoch 250/282\n",
            "39/39 [==============================] - 0s 905us/step - loss: 0.4404 - accuracy: 0.7765\n",
            "Epoch 251/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7861\n",
            "Epoch 252/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7957\n",
            "Epoch 253/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7774\n",
            "Epoch 254/282\n",
            "39/39 [==============================] - 0s 962us/step - loss: 0.4291 - accuracy: 0.7900\n",
            "Epoch 255/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7800\n",
            "Epoch 256/282\n",
            "39/39 [==============================] - 0s 942us/step - loss: 0.4757 - accuracy: 0.7736\n",
            "Epoch 257/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7968\n",
            "Epoch 258/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7855\n",
            "Epoch 259/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8128\n",
            "Epoch 260/282\n",
            "39/39 [==============================] - 0s 943us/step - loss: 0.4618 - accuracy: 0.8050\n",
            "Epoch 261/282\n",
            "39/39 [==============================] - 0s 929us/step - loss: 0.4459 - accuracy: 0.7921\n",
            "Epoch 262/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8036\n",
            "Epoch 263/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.7986\n",
            "Epoch 264/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8072\n",
            "Epoch 265/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7870\n",
            "Epoch 266/282\n",
            "39/39 [==============================] - 0s 895us/step - loss: 0.4209 - accuracy: 0.8122\n",
            "Epoch 267/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7513\n",
            "Epoch 268/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7912\n",
            "Epoch 269/282\n",
            "39/39 [==============================] - 0s 928us/step - loss: 0.4550 - accuracy: 0.7644\n",
            "Epoch 270/282\n",
            "39/39 [==============================] - 0s 922us/step - loss: 0.4664 - accuracy: 0.7604\n",
            "Epoch 271/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.8063\n",
            "Epoch 272/282\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7698\n",
            "Epoch 273/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.7977\n",
            "Epoch 274/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8061\n",
            "Epoch 275/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7876\n",
            "Epoch 276/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7974\n",
            "Epoch 277/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8027\n",
            "Epoch 278/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7869\n",
            "Epoch 279/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7661\n",
            "Epoch 280/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7800\n",
            "Epoch 281/282\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7941\n",
            "Epoch 282/282\n",
            "39/39 [==============================] - 0s 925us/step - loss: 0.4389 - accuracy: 0.7888\n",
            "24/24 [==============================] - 0s 941us/step - loss: 0.4327 - accuracy: 0.7930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEiIl7uDYBk1",
        "outputId": "225445e9-804b-4d6a-aad1-3dc9a0cb7191"
      },
      "source": [
        "print('Accuracy : %.2f' %(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 79.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5m3ZFKWdAwN",
        "outputId": "e2c57e41-0b99-41d7-cc30-8f2d2e65f6ef"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open('model.json',\"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"saved model to disk\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBw6TGCiraux"
      },
      "source": [
        "json_file = open('model.json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRZD3T_Nr1OC",
        "outputId": "ec9edf5b-a7dd-4a47-cc64-9626c3d36eba"
      },
      "source": [
        "model = model_from_json(loaded_model_json)\n",
        "model.load_weights(\"model.h5\")\n",
        "print(\"loaded model from disk\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9neJrMGr3w9",
        "outputId": "0aeebc2e-0dbc-4ce4-bdde-8ee599f23bce"
      },
      "source": [
        "predictions = model.predict_classes(x)\n",
        "for i in range(5,10):\n",
        "    print('%s => %d (expected %d)' %(x[i].tolist(), predictions[i], y[i]))\n",
        "    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] => 0 (expected 0)\n",
            "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] => 0 (expected 1)\n",
            "[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] => 0 (expected 0)\n",
            "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] => 1 (expected 1)\n",
            "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.232, 54.0] => 0 (expected 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi6My9cHr5z-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}